---
title: "ì„ í˜•íšŒê·€ ëª¨ë¸, Gradient Boostingì˜ ì¢…ë¥˜"
excerpt: "2022-11-16 Linear Regression, XBG, LightBG, Catboost"

# layout: post
categories:
  - TIL
tags:
  - python
  - EDA
  - Learning Machine
  - Feature Scaling
  - Encoding
  - Seaborn
  - Matplotlib
  - Feature Engineering
  - Linear Regression
  - Gradient Boosting
  - XBG
  - LightBG
  - Catboost
spotifyplaylist: spotify/playlist/2KaQr0nx66AX399ZLLuTVf?si=43a48325c8fc4b16
---
### **âš ï¸ í•´ë‹¹ ë‚´ìš©ì€ ë©‹ìŸì´ì‚¬ìì²˜ëŸ¼ AI School ì˜¤ëŠ˜ì½”ë“œ ë°•ì¡°ì€ ê°•ì‚¬ì˜ ìë£Œë¥¼ í† ëŒ€ë¡œ ì •ë¦¬í•œ ë‚´ìš©ì…ë‹ˆë‹¤.**
{% include spotifyplaylist.html id=page.spotifyplaylist %}


# 11/16 : Gradient Boostingì˜ ì¢…ë¥˜

[ì§€ë‚œ í¬ìŠ¤íŒ…](https://junstar21.github.io/til/hp,bz/)ì—ì„œ ì´ì–´ì§

## One-Hot-Encoding

```python
# ëª¨ë¸ì— ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ìˆ«ì ì´ì™¸ì˜ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸í•œë‹¤.
# ë³€í™˜í•  í”¼ì²˜ê°€ ë‚¨ì•„ìˆëŠ”ì§€ í™•ì¸í•œë‹¤.
df_test.select_dtypes(exclude="number")[:2]
```

![]({{ site.url }}{{ site.baseurl }}/assets/images/2022-11-16-boost model/Untitled.png)

## í•™ìŠµìš© ë°ì´í„°ì™€ ê²€ì¦ìš© ë°ì´í„° ë‚˜ëˆ„ê¸°

```python
X = df_train.drop(columns="y")
y = df_train["y"]
print(X.shape, y.shape)
display(X.head())
display(y.head())
```

## í•™ìŠµ, ê²€ì¦ì„¸íŠ¸ ë‚˜ëˆ„ê¸°

ì—¬ê¸°ì—ì„œëŠ” Hold-Out-validationì„ ì‚¬ìš©í•  ì˜ˆì •ì´ë‹¤. train_test_split ê¸°ëŠ¥ìœ¼ë¡œ train, validë¥¼ ë‚˜ëˆŒ ì˜ˆì •ì´ë‹¤. validë¥¼ ë§Œë“œëŠ” ì´ìœ ëŠ” ì œì¶œí•´ ë³´ê¸° ì „ì— ì–´ëŠ ì •ë„ì˜ ìŠ¤ì½”ì–´ê°€ ë‚˜ì˜¬ì§€ í™•ì¸í•´ë³´ê¸° ìœ„í•¨ì´ë‹¤. cross validationì„ ì‚¬ìš©í•˜ì§€ ì•Šê³  Hold-out-validationì„ ì‚¬ìš©í•  ì˜ˆì •ì´ë‹¤. Hold-out-validationì€ ì†ë„ê°€ cross validationì— ë¹„í•´ ë¹ ë¥´ë‹¤ëŠ”ê²Œ ì¥ì ì´ë‹¤.

train ë°ì´í„°ë¥¼ ì œì¶œí•´ë³´ê¸° ì „ì— ê²€ì¦í•´ë³´ê¸° ìœ„í•´ train ë°ì´í„°ì…‹ìœ¼ë¡œë§Œ ë‚˜ëˆ´ê¸° ë•Œë¬¸ì— X_train, X_validë¡œ ë‚˜ëˆ„ì–´ì¤€ë‹¤.

```python
from sklearn.model_selection import train_test_split

X_train, X_valid, y_train, y_valid = train_test_split(
X, y, test_size = 0.2, random_state=42)

#testë„ ë‚˜ì¤‘ì— í˜¼ë€ì´ ì—†ë„ë¡ ì´ë¦„ì„ ë§ì¶°ì¤€ë‹¤
X_test = df_test

X_train.shape, X_valid.shape, y_train.shape, y_valid.shape

ê²°ê³¼ê°’ : ((3367, 551), (842, 551), (3367,), (842,))
```

## ì„ í˜•íšŒê·€ëª¨ë¸

### [ì„ í˜•íšŒê·€](https://ko.wikipedia.org/wiki/%EC%84%A0%ED%98%95_%ED%9A%8C%EA%B7%80)ë€?

- í†µê³„í•™ì—ì„œ, ì„ í˜• íšŒê·€(ç·šå‹å›æ­¸, ì˜ì–´: linear regression)ëŠ” ì¢…ì† ë³€ìˆ˜ yì™€ í•œ ê°œ ì´ìƒì˜ ë…ë¦½ ë³€ìˆ˜ (ë˜ëŠ” ì„¤ëª… ë³€ìˆ˜) Xì™€ì˜ ì„ í˜• ìƒê´€ ê´€ê³„ë¥¼ ëª¨ë¸ë§í•˜ëŠ” íšŒê·€ë¶„ì„ ê¸°ë²•ì´ë‹¤.

```python
from sklearn.linear_model import LinearRegression

model = LinearRegression(n_jobs= -1)
model
```

## í•™ìŠµ

```python
model.fit(X_train, y_train)
```

R2ìŠ¤ì½”ì–´ë¡œ ì˜ˆì¸¡ì„ í•´ë³¸ë‹¤.

```python
model.score(X_valid, y_valid)

ê²°ê³¼ê°’ : -2.1203995300441175e+20
```

R2ìŠ¤ì½”ì–´ëŠ” 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì˜ˆì¸¡ì„ ì˜í•œ ê°’ì´ë‹¤. í•´ë‹¹ ê²°ê³¼ê°’ì€ ì˜ˆì¸¡ì´ ë§¤ìš° ì˜ ì•ˆëœ ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤. ì´ëŠ” ì„ í˜•íšŒê·€ ëª¨ë¸ì€ ì˜ˆì¸¡ë ¥ì´ ë–¨ì–´ì§€ê¸° ë•Œë¬¸ì´ë‹¤.

## ì˜ˆì¸¡ ë° ì œì¶œ

```python
# í•™ìŠµí•œ ë‚´ìš©ìœ¼ë¡œ ì˜ˆì¸¡ì„ ì§„í–‰í•œë‹¤
y_predict = model.predict(X_test)

# ì˜ˆì¸¡ê°’ì„ submissonì— ë„£ì–´ì„œ ì œì¶œì„ ì§„í–‰í•œë‹¤.
submission["y"] = y_predict
submission.to_csv("data/submit_lr.csv")
```

## ê²°ê³¼ í™•ì¸

![]({{ site.url }}{{ site.baseurl }}/assets/images/2022-11-16-boost model/Untitled 1.png)

êµ‰ì¥íˆ ì•ˆì¢‹ì€ ì ìˆ˜ê°€ ë‚˜ì˜¨ ê²ƒì„ í™•ì¸ í•  ìˆ˜ ìˆë‹¤. ì´ëŠ” ì˜ˆì¸¡ì´ ìƒë‹¹íˆ ì˜ëª»ëœ ê²ƒìœ¼ë¡œ íŒë‹¨í•  ìˆ˜ ìˆë‹¤.

ğŸ’¡ì„ í˜•íšŒê·€ë³´ë‹¤ íŠ¸ë¦¬ê³„ì—´ ëª¨ë¸ì„ ì‚¬ìš©í•˜ë©´ ê°™ì€ ë°ì´í„°ì…‹ì„ì—ë„ í›¨ì”¬ ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì¤€ë‹¤. ì´ìƒì¹˜ë„ í¬í•¨ë˜ì–´ìˆë‹¤. íšŒê·€ëª¨ë¸ì€ ì´ìƒì¹˜ì— ë¯¼ê°í•˜ê³  ë‹¤ë¥¸ ìˆ˜ì¹˜ë°ì´í„°ì— ë¹„í•´ ì „ì²˜ë¦¬ê°€ ë§ì´ í•„ìš”í•˜ë‹¤. ì„ í˜•íšŒê·€ëŠ” ê°„ë‹¨í•˜ê³  ì´í•´í•˜ê¸° ì‰½ë‹¤ëŠ” ì¥ì ì´ ìˆì§€ë§Œ, ì„¤ëª…ë ¥ì´ ë–¨ì–´ì§€ëŠ” ë‹¨ì ì´ ìˆë‹¤. ë”°ë¼ì„œ, ì„ í˜•íšŒê·€ì— ë§ëŠ” ë°ì´í„° ì…‹ì„ ì‚¬ìš©í•œë‹¤ë©´ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚¼ ìˆ˜ ìˆë‹¤.

ì§€ë‚œ í¬ìŠ¤íŠ¸ì—ì„œëŠ” ì›í•œ ì¸ì½”ë”©ì„ ë²”ì£¼í˜• ë³€ìˆ˜ì— í•´ì£¼ê³ , ìˆ˜ì¹˜ ë°ì´í„°ì™€ í•©ì¹˜ëŠ” ê³¼ì •ì„ ë°°ì› ë‹¤. ì´ë²ˆì—ëŠ” Ordinal ì¸ì½”ë”© ë°©ë²•ë„ ì•Œì•„ë³¸ë‹¤.
concat => ì¸ë±ìŠ¤ ê°’ì´ ë§ì§€ ì•Šìœ¼ë©´ ì œëŒ€ë¡œ ë³‘í•©ë˜ì§€ ì•Šì„ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ì¸ë±ìŠ¤ ê°’ì— ìœ ì˜ê°€ í•„ìš”í•˜ë‹¤. 

# **ë‹¤ì–‘í•œ ëŸ¬ë‹ë¨¸ì‹  ëª¨ë¸ì— ëŒ€í•œ ì‹¤ìŠµ**

ì´ë²ˆì—ëŠ” ë‹¤ì–‘í•œ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ ì‚¬ìš©í•´ë³´ë¡ í•œë‹¤. 

## ì´ìƒì¹˜ ì œê±°

ì •ë‹µê°’ yì˜ ì´ìƒì¹˜ë¥¼ í™•ì¸í•´ë³´ì.

```python
train[train["y"]>200]
```

![]({{ site.url }}{{ site.baseurl }}/assets/images/2022-11-16-boost model/Untitled 2.png)

í•˜ë‚˜ì˜ ì´ìƒì¹˜ê°€ í™•ì¸ëœë‹¤. í•´ë‹¹ ê°’ì„ ì œì™¸í•´ì£¼ì.

```python
# ì´ìƒì¹˜ë¥¼ ì œê±°í•˜ê³  ì‚¬ìš©í•œë‹¤.
train = train[train["y"]<200].copy()
train.shape

ê²°ê³¼ê°’ : (4208, 377)
```

## Feature engineering

### One-Hot-Encoding

```python
from sklearn.preprocessing import OneHotEncoder

ohe = OneHotEncoder(handle_unknown="ignore")
train_ohe = ohe.fit_transform(train.drop(columns="y"))
test_ohe = ohe.transform(test)

train_ohe.shape, test_ohe.shape

ê²°ê³¼ê°’ : ((4208, 919), (4209, 919))
```

## í•™ìŠµ, ê²€ì¦ ë°ì´í„°ì…‹ ë‚˜ëˆ„ê¸°

```python
# train ìœ¼ë¡œ X, y ë§Œë“¤ê¸°
X = train_ohe
y = train["y"]

X.shape, y.shape
ê²°ê³¼ê°’ : ((4208, 919), (4208,))

# train_test_splitì„ ì´ìš©í•´ X, y ê°’ì„ X_train, X_valid, y_train, y_valid ìœ¼ë¡œ ë‚˜ëˆˆë‹¤.
from sklearn.model_selection import train_test_split

X_train, X_valid, y_train, y_valid = train_test_split(
X, y, test_size = 0.33, random_state=42)

X_train.shape, X_valid.shape, y_train.shape, y_valid.shape
ê²°ê³¼ê°’ : ((2819, 919), (1389, 919), (2819,), (1389,))

# X_test
X_test = test_ohe

X_test.shape
ê²°ê³¼ê°’ : (4209, 919)
```

## ëª¨ë¸ ì‹¤ìŠµì„ ìœ„í•œ ëª¨ë¸ì˜ ë°°ê²½ ì´ë¡  ì´í•´

### Baggingê³¼ Boostingì˜ ì°¨ì´?

![]({{ site.url }}{{ site.baseurl }}/assets/images/2022-11-16-boost model/Untitled 3.png)

- Bagging : Baggingì€ í›ˆë ¨ì„¸íŠ¸ì—ì„œ ì¤‘ë³µì„ í—ˆìš©í•´ì„œ ìƒ˜í”Œë§í•˜ì—¬ ì—¬ëŸ¬ê°œ ëª¨ë¸ì„ í›ˆë ¨ í•˜ëŠ” ì•™ìƒë¸” ë°©ì‹ì´ë‹¤. ê°™ì€ í›ˆë ¨ ìƒ˜í”Œì„ ì—¬ëŸ¬ ê°œì˜ ëª¨ë¸ì— ê±¸ì³ ì‚¬ìš©í•´ì„œ ëª¨ë“  ëª¨ë¸ì´ í›ˆë ¨ì„ ë§ˆì¹˜ë©´ ì•™ìƒë¸”ì€ ëª¨ë“  ì˜ˆì¸¡ê¸°ì˜ ì˜ˆì¸¡ì„ ëª¨ì•„ì„œ ìƒˆë¡œìš´ ìƒ˜í”Œì— ëŒ€í•œ ì˜ˆì¸¡ì„ ë§Œë“¤ê²Œ ëœë‹¤.
- Boosting : ë¶€ìŠ¤íŒ…ì€ ì•½í•œ ëª¨ë¸ì„ ì—¬ëŸ¬ê°œ ì—°ê²°í•´ì„œ ê°•í•œ ëª¨ë¸ì„ ë§Œë“¤ì–´ ë‚´ê¸° ìœ„í•œ ì•™ìƒë¸” ë°©ì‹ì´ë‹¤. ë¶€ìŠ¤íŒ…ì˜ ì•„ì´ë””ì–´ëŠ” ì•ì˜ ëª¨ë¸ë“¤ì„ ë³´ì™„í•´ ë‚˜ê°€ë©´ì„œ ì¼ë ¨ì˜ ëª¨ë¸ë“¤ì„ í•™ìŠµì‹œì¼œ ë‚˜ê°€ëŠ” ê²ƒì´ë‹¤.
ë¶€ìŠ¤íŒ…ì—ì„œ ëŒ€í‘œì ì¸ ëª¨ë¸ ì¤‘ í•˜ë‚˜ëŠ” ì—ì´ë‹¤ì´ë‹¤. ì—ì´ë‹¤ ë¶€ìŠ¤íŠ¸ëŠ” ì•™ìƒë¸”ì— ì´ì „ê¹Œì§€ì˜ ì˜¤ì°¨ë¥¼ ë³´ì •í•˜ë„ë¡ ëª¨ë¸ì„ ìˆœì°¨ì ìœ¼ë¡œ ì¶”ê°€í•œë‹¤. ë°˜ë©´, ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…(ë°”ë¡œ ë‹¤ìŒì— ë‚˜ì˜¤ëŠ” ì£¼ì œì´ë‹¤)ì€ ì—ì´ë‹¤ ë¶€ìŠ¤íŠ¸ì™€ ë‹¬ë¦¬ ìƒ˜í”Œì˜ ê°€ì¤‘ì¹˜ë¥¼ ìˆ˜ì •í•˜ëŠ” ëŒ€ì‹  ì´ì „ ëª¨ë¸ì´ ë§Œë“  ì”ì—¬ ì˜¤ì°¨ì— ëŒ€í•´ ìƒˆë¡œìš´ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ê²Œ ëœë‹¤.

### **GBM, XGBoost, LightGBM, Catboost ë“± ëª¨ë¸ì´ë¦„ì— ë“¤ì–´ê°€ëŠ” â€˜Gâ€™ ëŠ” ë¬´ì—‡ì„ ì˜ë¯¸í• ê¹Œ?**

**Gradient(ê²½ì‚¬, ê¸°ìš¸ê¸°)**ë¥¼ ì˜ë¯¸í•œë‹¤. ì†ì‹¤í•¨ìˆ˜ ê·¸ë˜í”„(ì˜¤ì°¨ì˜ ì œê³±ì„ í–ˆì„ ë•Œ ê·¸ë˜í”„)ì—ì„œ ê·¸ë˜í”„ì˜ ê¸°ìš¸ê¸°ì— ë”°ë¼ ì–‘ì˜ ë°©í–¥ì¸ì§€, ìŒì˜ë°©í–¥ì¸ì§€ë¥¼ í™•ì¸í•˜ê³  ê¸°ìš¸ê¸°ì˜ ê°’ì´ ê°€ì¥ ë‚®ì€ ì§€ì (0)ìœ¼ë¡œ ê²½ì‚¬ë¥¼ íƒ€ê³  í•˜ê°•í•œë‹¤. ë¨¸ì‹ ëŸ¬ë‹ì—ì„œ ì˜ˆì¸¡ê°’ê³¼ ì •ë‹µê°’ê°„ì˜ ì°¨ì´ê°€ ì†ì‹¤í•¨ìˆ˜ì¸ë° ì´ í¬ê¸°ë¥¼ ìµœì†Œí™”ì‹œí‚¤ëŠ” íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ê¸° ìœ„í•´ ì‚¬ìš©í•œë‹¤.

![]({{ site.url }}{{ site.baseurl }}/assets/images/2022-11-16-boost model/Untitled 4.png)

- Learning step(learning rate) : Gradient ë‹¨ê³„ì—ì„œ ì˜¤ì°¨ì˜ ìµœì €ì ì„ ì°¾ì•„ê°ˆë•Œ ì–¼ë§ˆ ë‹¨ìœ„ë¡œ ì°¾ì•„ê°ˆì§€ë¥¼ ì„¤ì •í•œë‹¤. ì ì ˆí•œ stepì„ ì°¾ì•„ì•¼ í•˜ë©°, ë„ˆë¬´ ë†’ì€ stepì€ ìµœì €ì ì„ ì§€ë‚˜ì³ ë°œì‚°ì„ í•˜ê²Œ ë˜ë©°, ë„ˆë¬´ ë‚®ì€ stepì€ í•™ìŠµì†ë„ë¥¼ ëŠ¦ì¶”ê²Œ ë§Œë“ ë‹¤. ë˜í•œ, ì ì ˆí•œ stepë³´ë‹¤ ë†’ì€ step ë˜í•œ ë°œì‚°ì„ ìœ ë°œí•  ìˆ˜ ìˆë‹¤.
- Epoch :  n_estimatorsì™€ ê°™ì€ ê°œë…ì´ë‹¤. ë¶€ìŠ¤íŒ… íŠ¸ë¦¬ì—ì„œ n_estimatorsëŠ” ëª‡ ë²ˆì§¸ íŠ¸ë¦¬ì¸ì§€ë¥¼ ì˜ë¯¸í•œë‹¤.

[íŒŒì´ì„  ë¼ì´ë¸ŒëŸ¬ë¦¬ì„ í™œìš©í•œ ëŸ¬ë‹ë¨¸ì‹ ](https://preview2.hanbit.co.kr/books/rzmj/#p=1)

### GBM(Gradient Boosting Machine)

- íšŒê·€ ë˜ëŠ” ë¶„ë¥˜ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ì˜ˆì¸¡ëª¨í˜•ì´ë©°, ì˜ˆì¸¡ëª¨í˜•ì˜ ì•™ìƒë¸” ë°©ë²•ë¡  ì¤‘ ë¶€ìŠ¤íŒ… ê³„ì—´ì— ì†í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜
- ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ ì¤‘ì—ì„œë„ ê°€ì¥ ì˜ˆì¸¡ ì„±ëŠ¥ì´ ë†’ë‹¤ê³  ì•Œë ¤ì§„ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ GBMêµ¬í˜„í•œ íŒ¨í‚¤ì§€ë“¤ì´ ë‹¤ìˆ˜
- GBMì€ ê³„ì‚°ëŸ‰ì´ ìƒë‹¹íˆ ë§ì´ í•„ìš”í•œ ì•Œê³ ë¦¬ì¦˜ì´ê¸° ë•Œë¬¸ì—, ì´ë¥¼ í•˜ë“œì›¨ì–´ íš¨ìœ¨ì ìœ¼ë¡œ êµ¬í˜„í•˜ëŠ” ê²ƒì´ í•„ìš”

**íŠ¹ì§•**

- ëœë¤ í¬ë ˆìŠ¤íŠ¸ì™€ ë‹¤ë¥´ê²Œ ë¬´ì‘ìœ„ì„±ì´ ì—†ë‹¤.
- ë§¤ê°œë³€ìˆ˜ë¥¼ ì˜ ì¡°ì •í•´ì•¼ í•˜ê³  í›ˆë ¨ ì‹œê°„ì´ ê¸¸ë‹¤.
- ë°ì´í„°ì˜ ìŠ¤ì¼€ì¼ì— êµ¬ì• ë°›ì§€ ì•ŠëŠ”ë‹¤.
- ê³ ì°¨ì›ì˜ í¬ì†Œí•œ ë°ì´í„°ì— ì˜ ì‘ë™í•˜ì§€ ì•ŠëŠ”ë‹¤.

**ğŸ¤” GBM ì€ ì™œ ëœë¤ í¬ë ˆìŠ¤íŠ¸ì™€ ë‹¤ë¥´ê²Œ ë¬´ì‘ìœ„ì„±ì´ ì—†ì„ê¹Œ?**

![]({{ site.url }}{{ site.baseurl }}/assets/images/2022-11-16-boost model/Untitled 5.png)

ì´ì „ ì˜¤ì°¨ë¥¼ ë³´ì™„í•´ì„œ ë§Œë“¤ê¸° ë•Œë¬¸ì— ë¬´ì‘ìœ„ì„±ì´ ì—†ë‹¤. ì´ì „ ë‹¨ê³„ì— í‹€ë¦° ê²°ê³¼ë§Œ ë°›ì•„ì„œ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬ë°›ê³  ì˜ˆì¸¡ì„ ì§„í–‰í•˜ëŠ” í˜•íƒœì´ê¸° ë•Œë¬¸ì´ë‹¤.

## GBM(Gradient Boosting Machine) íŠ¸ë¦¬ ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡

```python
# ëª¨ë¸ í˜¸ì¶œ
from sklearn.ensemble import GradientBoostingRegressor
model_gbt = GradientBoostingRegressor(random_state=42)

# í•™ìŠµ
model_gbt.fit(X_train, y_train)

# valid score
gbt_score= model_gbt.score(X_valid, y_valid)

gbt_score
ê²°ê³¼ê°’: 0.5430438083177107

# ì˜ˆì¸¡
y_prid = model_gbt.predict(X_test)

# ì œì¶œ
submission["y"] = y_prid

file_name = "ë³¸ì¸ì´ ì €ì¥í•˜ê³  ì‹¶ì€ ìœ„ì¹˜/submission.csv"
```

![]({{ site.url }}{{ site.baseurl }}/assets/images/2022-11-16-boost model/Untitled 6.png)

## **ì—‘ìŠ¤íŠ¸ë¼ íŠ¸ë¦¬ ëª¨ë¸(Extremely Randomized Tree) í•™ìŠµ ë° ì˜ˆì¸¡**

```python
# sklearn.ensembleì˜ ExtraTreesRegressorëŠ” ì•™ìƒë¸” ëª¨ë¸ ì¤‘ ì—‘ìŠ¤íŠ¸ë¼ íŠ¸ë¦¬ ëª¨ë¸ì„ êµ¬í˜„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
from sklearn.ensemble import ExtraTreesRegressor
model_et = ExtraTreesRegressor(random_state=42)

# ëª¨ë¸ì„ í•™ìŠµ
model_et.fit(X_train, y_train)

# valid score
et_score = model_et.score(X_valid, y_valid)
et_score
ê²°ê³¼ê°’ : 0.27084420987554814

# ì˜ˆì¸¡
y_et_pred = model_et.predict(X_test)

#ì œì¶œì€ GBMê³¼ ë™ì¼í•˜ê²Œ ì§„í–‰í•œë‹¤.
```

![]({{ site.url }}{{ site.baseurl }}/assets/images/2022-11-16-boost model/Untitled 7.png)

# Boosting model input

**ğŸ¤” ë¶€ìŠ¤íŒ… ê³„ì—´ ëª¨ë¸ì€ ì„¤ì¹˜ê°€ ì‹¤íŒ¨í•˜ëŠ” ê²½ìš°ê°€ ë°œìƒí•˜ëŠ”ë° ì™œì¼ê¹Œ?**

- ê¸°ë³¸ì ìœ¼ë¡œ ë‹¤ë¥¸ ì–¸ì–´ í™˜ê²½ì—ì„œ ë§Œë“¤ì–´ì§„ ëª¨ë¸ì´ë‹¤. ê·¸ëŸ¬í•˜ë‹¤ë³´ë‹ˆ, pythonì—ì„œëŠ” pyhton APIë¥¼ í†µí•´ì„œ êµ¬ë™ë˜ëŠ” ëª¨ë¸ì´ë‹¤.
- ê¸°ì¡´ì— í•´ë‹¹ ì–¸ì–´ í™˜ê²½ ë„êµ¬ë¥¼ ì„¤ì¹˜í–ˆë‹¤ë©´ ë¹„êµì  ì˜ ì„¤ì¹˜ê°€ ë˜ì§€ë§Œ ê·¸ë ‡ì¹˜ ì•Šì€ ê²½ìš° ì„¤ì¹˜ì— ì‹¤íŒ¨í•˜ëŠ” ê²½ìš°ê°€ ë§ë‹¤.
- condaëŠ” ë¹„êµì  íŒ¨í‚¤ì§•ì´ ì˜ ë˜ì–´ ìˆì–´ì„œ ê´€ë ¨ëœ í™˜ê²½ì„ ì˜ êµ¬ì„±í•´ ì¤€ë‹¤. ê·¸ë˜ì„œ ê°€ê¸‰ì ì´ë©´ conda í™˜ê²½ì—ì„œ ì„¤ì¹˜í•˜ëŠ” ê²ƒì´ ì¢‹ë‹¤.
- Bagging ë°©ì‹ì€ ë¶€íŠ¸ìŠ¤íŠ¸ë˜í•‘ì„ í•´ì„œ íŠ¸ë¦¬ë¥¼ ë³‘ë ¬ì ìœ¼ë¡œ ì—¬ëŸ¬ ê°œ ë§Œë“¤ê¸° ë•Œë¬¸ì— ì˜¤ë²„í”¼íŒ… ë¬¸ì œì— ì¢€ ë” ì í•©í•˜ë‹¤.
- ê°œë³„ íŠ¸ë¦¬ì˜ ë‚®ì€ ì„±ëŠ¥ì´ ë¬¸ì œì¼ ë•ŒëŠ” ì´ì „ íŠ¸ë¦¬ì˜ ì˜¤ì°¨ë¥¼ ë³´ì™„í•´ ê°€ë©´ì„œ ë§Œë“¤ê¸° ë•Œë¬¸ì— ë¶€ìŠ¤íŒ…ì´ ì¢€ ë” ì í•©í•˜ë‹¤.

## [XGBoost](https://xgboost.readthedocs.io/en/stable/parameter.html)

- XGBoostëŠ” C++ , Java , Python , R , Julia , Perl ë° Scala ìš© ì •ê·œí™” ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… í”„ë ˆì„ì›Œí¬ë¥¼ ì œê³µ í•˜ëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ ì†Œí”„íŠ¸ì›¨ì–´ ë¼ì´ë¸ŒëŸ¬ë¦¬
- xgboostëŠ” GBTì—ì„œ ë³‘ë ¬ í•™ìŠµì„ ì§€ì›í•˜ì—¬ í•™ìŠµ ì†ë„ê°€ ë¹¨ë¼ì§„ ëª¨ë¸
- ê¸°ë³¸ GBTì— ë¹„í•´ ë” íš¨ìœ¨ì ì´ê³ , ë‹¤ì–‘í•œ ì¢…ë¥˜ì˜ ë°ì´í„°ì— ëŒ€ì‘í•  ìˆ˜ ìˆìœ¼ë©° ì´ì‹ì„±ì´ ë†’ë‹¤.
- ë¨¸ì‹  ëŸ¬ë‹ ëŒ€íšŒì—ì„œ ìš°ìŠ¹í•œ ë§ì€ íŒ€ì´ ì„ íƒí•œ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ìµœê·¼ ë§ì€ ì¸ê¸°ì™€ ì£¼ëª©ì„ ë°›ê³  ìˆë‹¤.

| ì¥ì  | ë‹¨ì  |
| --- | --- |
| GBM ëŒ€ë¹„ ë¹ ë¥¸ ìˆ˜í–‰ì‹œê°„(ë³‘ë ¬ ì²˜ë¦¬) | XGBoostëŠ” GBMì— ë¹„í•´ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ê³  ë¹„êµì  ë¹ ë¥´ì§€ë§Œ ê·¸ë˜ë„ ì—¬ì „íˆ í•™ìŠµì‹œê°„ì´ ëŠë¦¼ |
| ê³¼ì í•© ê·œì œ(Regularization)
â—¦ í‘œì¤€ GBM ê²½ìš° ê³¼ì í•© ê·œì œê¸°ëŠ¥ì´ ì—†ìœ¼ë‚˜, XGBoostëŠ” ìì²´ì— ê³¼ì í•© ê·œì œ ê¸°ëŠ¥ìœ¼ë¡œ ê°•í•œ ë‚´êµ¬ì„±ì„ ì§€ë‹˜ | Hyper Parameter ìˆ˜ê°€ ë§ì•„ Hyper Parameter íŠœë‹ì„ í•˜ê²Œë˜ë©´ ì‹œê°„ì´ ë”ìš± ì˜¤ë˜ ê±¸ë¦¼ |
| ë¶„ë¥˜ì™€ íšŒê·€ì˜ì—­ì—ì„œ ë›°ì–´ë‚œ ì˜ˆì¸¡ ì„±ëŠ¥ ë°œíœ˜(ê´‘ë²”ìœ„í•œ ì˜ì—­) | ëª¨ë¸ì˜ Overfitting |
| Early Stopping(ì¡°ê¸° ì¢…ë£Œ) ê¸°ëŠ¥ì´ ìˆìŒ |  |
| ë‹¤ì–‘í•œ ì˜µì…˜(Hyper Parameter) ì„ ì œê³µí•˜ë©° Customizingì´ ìš©ì´ |  |

## LightGBM

- Light Gradient Boosting Machineì˜ ì•½ìì¸ LightGBM ì€ ì›ë˜ Microsoftì—ì„œ ê°œë°œí•œ ë¨¸ì‹  ëŸ¬ë‹ì„ ìœ„í•œ ì˜¤í”ˆ ì†ŒìŠ¤ ë¶„ì‚° ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… í”„ë ˆì„ì›Œí¬
- ê²°ì • íŠ¸ë¦¬ ì•Œê³ ë¦¬ì¦˜ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ë©° ìˆœìœ„ ì§€ì • , ë¶„ë¥˜ ë° ê¸°íƒ€ ê¸°ê³„ í•™ìŠµ ì‘ì—…ì— ì‚¬ìš©
- ê°œë°œ ì´ˆì ì€ ì„±ëŠ¥ê³¼ í™•ì¥ì„±ì— ìˆë‹¤.

| ì¥ì  | ë‹¨ì  |
| --- | --- |
| ë” ë¹ ë¥¸ í›ˆë ¨ ì†ë„ì™€ ë” ë†’ì€ íš¨ìœ¨ì„± | LightGBMì€ overfitting (ê³¼ì í•©)ì— ë¯¼ê°í•˜ê³  ì‘ì€ ë°ì´í„°ì— ëŒ€í•´ì„œ ê³¼ì í•©ë˜ê¸° ì‰¬ì›€ |
| ì ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ |  |
| ë” ë‚˜ì€ ì •í™•ë„ |  |
| ë³‘ë ¬, ë¶„ì‚° ë° GPU í•™ìŠµ ì§€ì› |  |
| ëŒ€ê·œëª¨ ë°ì´í„°ë¥¼ ì²˜ë¦¬ |  |

## CatBoost

- CatBoostëŠ” Yandexì—ì„œ ê°œë°œí•œ ì˜¤í”ˆ ì†ŒìŠ¤ ì†Œí”„íŠ¸ì›¨ì–´ ë¼ì´ë¸ŒëŸ¬ë¦¬
- ê¸°ì¡´ ì•Œê³ ë¦¬ì¦˜ê³¼ ë¹„êµí•˜ì—¬ ìˆœì—´ ê¸°ë°˜ ëŒ€ì•ˆì„ ì‚¬ìš©í•˜ì—¬ ë²”ì£¼í˜• ê¸°ëŠ¥ì„ í•´ê²°í•˜ë ¤ê³  ì‹œë„ í•˜ëŠ” ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… í”„ë ˆì„ì›Œí¬ë¥¼ ì œê³µ
- ë‹¤ìŒê³¼ ê°™ì€ ì¥ì ì´ ìˆë‹¤.
    - ë²”ì£¼í˜• ê¸°ëŠ¥ì— ëŒ€í•œ ê¸°ë³¸ ì²˜ë¦¬
    - ë¹ ë¥¸ GPU í›ˆë ¨
    - ëª¨ë¸ ë° ê¸°ëŠ¥ ë¶„ì„ì„ ìœ„í•œ ì‹œê°í™” ë° ë„êµ¬
    - ë” ë¹ ë¥¸ ì‹¤í–‰ì„ ìœ„í•´ ë¬´ì‹œ íŠ¸ë¦¬ ë˜ëŠ” ëŒ€ì¹­ íŠ¸ë¦¬ ì‚¬ìš©
    - ê³¼ì í•©ì„ ê·¹ë³µí•˜ê¸° ìœ„í•´ ìˆœì„œê°€ ìˆëŠ” ë¶€ìŠ¤íŒ…ì„ ì‚¬ìš©