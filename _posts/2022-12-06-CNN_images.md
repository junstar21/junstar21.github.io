---
title: "CNN :ì´ë¯¸ì§€ ë¶„ë¥˜"
excerpt: "2022-12-06 CNN : catagorize images"

# layout: post
categories:
  - TIL
tags:
  - python
  - Deep Learning
  - CNN
  - Convolution
  - Padding
  - Kernal size
  - Pooling
spotifyplaylist: spotify/playlist/2KaQr0nx66AX399ZLLuTVf?si=43a48325c8fc4b16
---
### **âš ï¸ í•´ë‹¹ ë‚´ìš©ì€ ë©‹ìŸì´ì‚¬ìì²˜ëŸ¼ AI School ì˜¤ëŠ˜ì½”ë“œ ë°•ì¡°ì€ ê°•ì‚¬ì˜ ìë£Œë¥¼ í† ëŒ€ë¡œ ì •ë¦¬í•œ ë‚´ìš©ì…ë‹ˆë‹¤.**

# [Tensorflow ì´ë¯¸ì§€ë¶„ë¥˜ íŠœí† ë¦¬ì–¼](https://www.tensorflow.org/tutorials/images/classification)

ìµœì´ˆì˜ CNN : LeNet

## ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜¸ì¶œ

```python
import matplotlib.pyplot as plt
import numpy as np
import PIL
import tensorflow as tf

from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
```

## **ë°ì´í„°ì„¸íŠ¸ ë‹¤ìš´ë¡œë“œ ë° íƒìƒ‰í•˜ê¸°**

ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” ì•½ 3,700ì¥ì˜ ê½ƒ ì‚¬ì§„ ë°ì´í„°ì„¸íŠ¸ë¥¼ ì‚¬ìš©í•œë‹¤. ë°ì´í„°ì„¸íŠ¸ì—ëŠ” í´ë˜ìŠ¤ë‹¹ í•˜ë‚˜ì”© 5ê°œì˜ í•˜ìœ„ ë””ë ‰í„°ë¦¬ê°€ ì¡´ì¬í•œë‹¤.

```
flower_photo/
Â Â daisy/
Â Â dandelion/
Â Â roses/
Â Â sunflowers/
Â Â tulips/
```

```python
import pathlib
dataset_url = "https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz"
data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)
data_dir = pathlib.Path(data_dir)
```

```python
image_count = len(list(data_dir.glob('*/*.jpg')))
print(image_count)

ê²°ê³¼ê°’ : 3670
```

ì¥ë¯¸ë¥¼ í™•ì¸í•´ë³¸ë‹¤.

```python
roses = list(data_dir.glob('roses/*'))
PIL.Image.open(str(roses[0]))
```

![]({{ site.url }}{{ site.baseurl }}/assets/images/2022-12-06-CNN_images/Untitled.png)

```python
PIL.Image.open(str(roses[1]))
```

![]({{ site.url }}{{ site.baseurl }}/assets/images/2022-12-06-CNN_images/Untitled 1.png)

íŠ¤ë¦½ë„ í™•ì¸í•´ë³¸ë‹¤.

```python
tulips = list(data_dir.glob('tulips/*'))
PIL.Image.open(str(tulips[0]))
```

![]({{ site.url }}{{ site.baseurl }}/assets/images/2022-12-06-CNN_images/Untitled 2.png)

```python
PIL.Image.open(str(tulips[1]))
```

![]({{ site.url }}{{ site.baseurl }}/assets/images/2022-12-06-CNN_images/Untitled 3.png)

**ğŸ¤” íŠ¤ë¦½ì˜ ê²½ìš° ì´ ì´ë¯¸ì§€ë¥¼ í•™ìŠµí•  ê²½ìš° ì–´ë–¤ ë¬¸ì œê°€ ë°œìƒí• ê¹Œ?**

íŠ¤ë¦½ì´ ë„ˆë¬´ ë§ê±°ë‚˜ íŠ¤ë¦½ì´ ì•„ë‹Œ ë¶€ë¶„ë“¤ì´ ë§ë‹¤. ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ë¶„ë¥˜í•  ë•Œë„ ì „ì²˜ë¦¬ê°€ ì¤‘ìš”í•˜ë‹¤.

## **Keras ìœ í‹¸ë¦¬í‹°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ë¡œë“œí•˜ê¸°**

- ìœ ìš©í•œÂ `tf.keras.utils.image_dataset_from_directory`ìœ í‹¸ë¦¬í‹°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë””ìŠ¤í¬ì—ì„œ ì´ëŸ¬í•œ ì´ë¯¸ì§€ë¥¼ ë¡œë“œ
- ë””ìŠ¤í¬ì˜ ì´ë¯¸ì§€ ë””ë ‰í„°ë¦¬ì—ì„œÂ `tf.data.Dataset`ë¡œ ì´ë™

### ë°ì´í„°ì„¸íŠ¸ ë§Œë“¤ê¸°

ëª‡ ê°€ì§€ ë§¤ê°œë³€ìˆ˜ë¥¼ ì •ì˜í•œë‹¤.

```python
# ë°°ì—´ì— ë‹¤ë¥¸ê°’ì´ ë“¤ì–´ê°€ë©´ ê³„ì‚°ì´ ë¶ˆê°€í•˜ê¸° ë•Œë¬¸ì— ê°’ì„ ê³ ì •

batch_size = 32
img_height = 180
img_width = 180
```

PIL , OpenCV ë“±ì„ ë‚´ë¶€ì—ì„œ ì‚¬ìš©í•˜ê³  ìˆëŠ”ë° ìš°ë¦¬ê°€ í¬í† ìƒµì—ì„œ ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆ ì¤„ì´ëŠ” ê²ƒ ì²˜ëŸ¼ ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆë¥¼ ì¡°ì •í•´ì¤€ë‹¤. ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆ í¬ê¸°ì— ë”°ë¥¸ ì¥ë‹¨ì ì´ ì¡´ì¬í•œë‹¤.

- ì‘ì€ ì‚¬ì´ì¦ˆ : ì´ë¯¸ì§€ê°€ ì™œê³¡ë˜ê±°ë‚˜ ì†ì‹¤ë  ìˆ˜ë„ ìˆì§€ë§Œ ê³„ì‚°ëŸ‰ì´ ì¤„ì–´ë“¤ê¸° ë•Œë¬¸ì— ë¹ ë¥´ê²Œ í•™ìŠµí•œë‹¤.
- í° ì‚¬ì´ì¦ˆ : ì‘ì€ ì´ë¯¸ì§€ë¥¼ ëŠ˜ë¦¬ë©´ ì™œê³¡ë  ìˆ˜ë„ ìˆì§€ë§Œ ë” ìì„¸íˆ í•™ìŠµí•˜ê¸° ë•Œë¬¸ì— ì„±ëŠ¥ì´ ì¢‹ì„ ìˆ˜ ìˆì§€ë§Œ, ê³„ì‚°ì´ ì˜¤ë˜ ê±¸ë¦°ë‹¤.

Trainê³¼ Validation setì„ ë§Œë“¤ì–´ì¤€ë‹¤.

```python
train_ds = tf.keras.utils.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  subset="training",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

ê²°ê³¼ê°’:
Found 3670 files belonging to 5 classes.
Using 2936 files for training.
```

```python
val_ds = tf.keras.utils.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  subset="validation",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

ê²°ê³¼ê°’ :
Found 3670 files belonging to 5 classes.
Using 734 files for validation.
```

í´ë˜ìŠ¤ì˜ ì´ë¦„ì„ í™•ì¸í•´ë³¸ë‹¤.

```
class_names = train_ds.class_names
print(class_names)
```

## **ë°ì´í„° ì‹œê°í™”í•˜ê¸°**

ì²˜ìŒ 9ê°œì˜ ì´ë¯¸ì§€ë¥¼ í™•ì¸í•´ë³¸ë‹¤.

```python
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 10))
for images, labels in train_ds.take(1):
  for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(images[i].numpy().astype("uint8"))
    plt.title(class_names[labels[i]])
    plt.axis("off")
```

![]({{ site.url }}{{ site.baseurl }}/assets/images/2022-12-06-CNN_images/Untitled 4.png)

## **ì„±ëŠ¥ì„ ë†’ì´ë„ë¡ ë°ì´í„°ì„¸íŠ¸ êµ¬ì„±í•˜ê¸°**

- `Dataset.cache()`ëŠ” ì²« epoch ë™ì•ˆ ë””ìŠ¤í¬ì—ì„œ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•œ í›„ ì´ë¯¸ì§€ë¥¼ ë©”ëª¨ë¦¬ì— ìœ ì§€í•œë‹¤. ì´ë ‡ê²Œ í•˜ë©´ ëª¨ë¸ì„ í›ˆë ¨í•˜ëŠ” ë™ì•ˆ ë°ì´í„°ì„¸íŠ¸ê°€ ë³‘ëª© ìƒíƒœê°€ ë˜ì§€ ì•ŠëŠ”ë‹¤. ë°ì´í„°ì„¸íŠ¸ê°€ ë„ˆë¬´ ì»¤ì„œ ë©”ëª¨ë¦¬ì— ë§ì§€ ì•ŠëŠ” ê²½ìš°, ì´ ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì„±ëŠ¥ì´ ë†’ì€ ì˜¨ë””ìŠ¤í¬ ìºì‹œë¥¼ ìƒì„±í•  ìˆ˜ë„ ìˆë‹¤.
- `Dataset.prefetch`ëŠ” í›ˆë ¨í•˜ëŠ” ë™ì•ˆ ë°ì´í„° ì „ì²˜ë¦¬ ë° ëª¨ë¸ ì‹¤í–‰ì„ ì¤‘ì²©ì‹œí‚µë‹ˆë‹¤.

```python
AUTOTUNE = tf.data.AUTOTUNE

train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)
```

## **ë°ì´í„° í‘œì¤€í™”í•˜ê¸°**

```python
# 0~1 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ ë§Œë“¤ì–´ì£¼ê¸°
normalization_layer = layers.Rescaling(1./255)
```

```python
normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))
image_batch, labels_batch = next(iter(normalized_ds))
first_image = image_batch[0]
# Notice the pixel values are now in `[0,1]`.
print(np.min(first_image), np.max(first_image))
```

ë¯¸ë¦¬ ë°ì´í„° í‘œì¤€í™”ë¥¼ ì‹œì¼œì£¼ì—ˆì§€ë§Œ, ëª¨ë¸ì—ì„œë„ í‘œì¤€í™”ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.

## **ê¸°ë³¸ Keras ëª¨ë¸**

### **ëª¨ë¸ ë§Œë“¤ê¸°**

```python
num_classes = len(class_names)

model = Sequential([
  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),
  layers.Conv2D(filters = 16, kernel_size = 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(filters = 32, kernel_size = 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(filters = 64, kernel_size = 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Flatten(),
  layers.Dense(128, activation='relu'),
  layers.Dense(num_classes)
])
```

### ëª¨ë¸ ì»´íŒŒì¼í•˜ê¸°

`tf.keras.optimizers.Adam`ì˜µí‹°ë§ˆì´ì €ì™€Â `tf.keras.losses.SparseCategoricalCrossentropy`ì†ì‹¤ í•¨ìˆ˜ë¥¼ ì„ íƒí•œë‹¤.

```python
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
```

### ëª¨ë¸ í›ˆë ¨í•˜ê¸°

```python
epochs=10
history = model.fit(
  train_ds,
  validation_data=val_ds,
  epochs=epochs
)
```

## í›ˆë ¨ ê²°ê³¼ ì‹œê°í™”

```python
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(epochs)

plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()
```

![]({{ site.url }}{{ site.baseurl }}/assets/images/2022-12-06-CNN_images/Untitled 5.png)

Validation Lossë¥¼ ë³´ë©´ í˜„ì¬ ëª¨ë¸ì€ ì˜¤ë²„í”¼íŒ…ì´ ì¼ì–´ë‚œ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. í•œ ê°€ì§€ ì´ìœ ë¡œ ë‹¨ì •í•˜ê¸°ëŠ” ì–´ë µì§€ë§Œ ê°€ì¥ ì„±ëŠ¥ì´ ì•ˆ ì¢‹ê²Œ ë‚˜ì˜¨ ì¤‘ì ì ì¸ ì´ìœ ë¥¼ ì°¾ëŠ”ë‹¤ë©´ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ê°€ ì œëŒ€ë¡œ ë˜ì–´ìˆì§€ ì•Šì•„ì„œ ì¼ì–´ë‚œ ê²ƒìœ¼ë¡œ íŒë‹¨ëœë‹¤. í›ˆë ¨ ì˜ˆì œê°€ ì ì„ ë•Œ ëª¨ë¸ì€ ìƒˆë¡œìš´ ì˜ˆì œì—ì„œ ëª¨ë¸ì˜ ì„±ëŠ¥ì— ë¶€ì •ì ì¸ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ì •ë„ê¹Œì§€ í›ˆë ¨ ì˜ˆì œì˜ ë…¸ì´ì¦ˆë‚˜ ì›ì¹˜ ì•ŠëŠ” ì„¸ë¶€ê¹Œì§€ í•™ìŠµí•˜ê²Œ ëœë‹¤. ì´ëŠ” ëª¨ë¸ì´ ìƒˆ ë°ì´í„°ì„¸íŠ¸ì—ì„œ ì¼ë°˜í™”í•˜ëŠ” ë° ì–´ë ¤ì›€ì´ ìˆìŒì„ ì˜ë¯¸í•œë‹¤. í›ˆë ¨ ê³¼ì •ì—ì„œ ê³¼ëŒ€ì í•©ì„ ë§‰ëŠ” ì—¬ëŸ¬ ê°€ì§€ ë°©ë²•ë“¤ì´ ìˆê³ , ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” ë°ì´í„° ì¦ê°•ì„ ì‚¬ìš©í•˜ê³  ëª¨ë¸ì— ë“œë¡­ì•„ì›ƒì„ ì¶”ê°€í•œë‹¤.

## ë°ì´í„° ì¦ê°•

- í•™ìŠµ ë°ì´í„°ê°€ ì ì–´ì„œ ê³¼ëŒ€ì í•©ì´ ìš°ë ¤ë  ë•Œ, ê¸°ì¤€ ë°ì´í„°ë¡œë¶€í„° ì´ë¯¸ì§€ë¥¼ ëœë¤í•˜ê²Œ ìƒì„±í•˜ì—¬ ë°ì´í„°ì˜ ìˆ˜ë¥¼ ì¦ê°•í•œë‹¤.
- Keras ì „ì²˜ë¦¬ ë ˆì´ì–´Â `tf.keras.layers.RandomFlip`,Â `tf.keras.layers.RandomRotation`,Â `tf.keras.layers.RandomZoom`ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ì¦ê°•ì„ êµ¬í˜„í•œë‹¤. ë°ì´í„°ë¥¼ ì ‘ê³ , ëŒë¦¬ê³ , ë‹¹ê¸´ë‹¤.

![]({{ site.url }}{{ site.baseurl }}/assets/images/2022-12-06-CNN_images/Untitled 6.png)

- ì¶œì²˜ : [Data Augmentation for Object Detection | Kaggle](https://www.kaggle.com/code/ankursingh12/data-augmentation-for-object-detection/notebook)

```python
data_augmentation = keras.Sequential(
  [
    layers.RandomFlip("horizontal",
                      input_shape=(img_height,
                                  img_width,
                                  3)),
    layers.RandomRotation(0.1),
    layers.RandomZoom(0.1),
  ]
)
```

ë™ì¼í•œ ì´ë¯¸ì§€ì— ë°ì´í„° ì¦ê°•ì„ ì—¬ëŸ¬ ë²ˆ ì ìš©í•˜ì—¬ ëª‡ ê°€ì§€ ì¦ê°• ì˜ˆì œë¥¼ ì‹œê°í™”í•˜ì. ì‹¤í–‰í•  ë•Œë§ˆë‹¤ ë‹¤ë¥¸ ì´ë¯¸ì§€ì˜ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ìˆë‹¤.

```python
plt.figure(figsize=(10, 10))
for images, _ in train_ds.take(1):
  for i in range(9):
    augmented_images = data_augmentation(images)
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(augmented_images[0].numpy().astype("uint8"))
    plt.axis("off")
```

![]({{ site.url }}{{ site.baseurl }}/assets/images/2022-12-06-CNN_images/Untitled 7.png)

## Dropout

ê³¼ëŒ€ì í•©ì„ ì¤„ì´ëŠ” ë˜ ë‹¤ë¥¸ ê¸°ìˆ ì€ ë„¤íŠ¸ì›Œí¬ì—Â [dropout](https://developers.google.com/machine-learning/glossary#dropout_regularization){:.external} ì •ê·œí™”ë¥¼ ë„ì…í•˜ëŠ” ê²ƒì´ë‹¤.

ë“œë¡­ì•„ì›ƒì„ ë ˆì´ì–´ì— ì ìš©í•˜ë©´, í›ˆë ¨ í”„ë¡œì„¸ìŠ¤ ì¤‘ì— ë ˆì´ì–´ì—ì„œ ì—¬ëŸ¬ ì¶œë ¥ ë‹¨ìœ„ê°€ ë¬´ì‘ìœ„ë¡œ ë“œë¡­ì•„ì›ƒí•œë‹¤.(í™œì„±í™”ë¥¼ 0ìœ¼ë¡œ ì„¤ì •). ë“œë¡­ì•„ì›ƒì€ 0.1, 0.2, 0.4 ë“±ì˜ í˜•ì‹ìœ¼ë¡œ ì†Œìˆ˜ë¥¼ ì…ë ¥ ê°’ìœ¼ë¡œ ì‚¬ìš©í•˜ë©°, ì´ëŠ” ì ìš©ëœ ë ˆì´ì–´ì—ì„œ ì¶œë ¥ ë‹¨ìœ„ì˜ 10%, 20% ë˜ëŠ” 40%ë¥¼ ì„ì˜ë¡œ ì œê±°í•˜ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤.

ì¦ê°• ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ í›ˆë ¨í•˜ê¸° ì „ì—Â `tf.keras.layers.Dropout`ì„ ì‚¬ìš©í•˜ì—¬ ìƒˆë¡œìš´ ì‹ ê²½ë§ì„ ìƒì„±í•œë‹¤. Dropoutì„ ì ìš©í•œ ëª¨ë¸ì„ ë§Œë“¤ì–´ì£¼ë„ë¡ í•œë‹¤.

```python
model = Sequential([
  data_augmentation,
  layers.Rescaling(1./255),
  layers.Conv2D(16, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(32, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(64, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Dropout(0.2),
  layers.Flatten(),
  layers.Dense(128, activation='relu'),
  layers.Dense(num_classes, name="outputs")
])
```

## **ëª¨ë¸ ì»´íŒŒì¼ ë° í›ˆë ¨í•˜ê¸°**

```python
# ì»´íŒŒì¼
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
```

```python
# ëª¨ë¸ ìš”ì•½
model.summary()
```

```
ê²°ê³¼ê°’:
Model: "sequential_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 sequential_1 (Sequential)   (None, 180, 180, 3)       0         
                                                                 
 rescaling_2 (Rescaling)     (None, 180, 180, 3)       0         
                                                                 
 conv2d_3 (Conv2D)           (None, 180, 180, 16)      448       
                                                                 
 max_pooling2d_3 (MaxPooling  (None, 90, 90, 16)       0         
 2D)                                                             
                                                                 
 conv2d_4 (Conv2D)           (None, 90, 90, 32)        4640      
                                                                 
 max_pooling2d_4 (MaxPooling  (None, 45, 45, 32)       0         
 2D)                                                             
                                                                 
 conv2d_5 (Conv2D)           (None, 45, 45, 64)        18496     
                                                                 
 max_pooling2d_5 (MaxPooling  (None, 22, 22, 64)       0         
 2D)                                                             
                                                                 
 dropout (Dropout)           (None, 22, 22, 64)        0         
                                                                 
 flatten_1 (Flatten)         (None, 30976)             0         
                                                                 
 dense_2 (Dense)             (None, 128)               3965056   
                                                                 
 outputs (Dense)             (None, 5)                 645       
                                                                 
=================================================================
Total params: 3,989,285
Trainable params: 3,989,285
Non-trainable params: 0
_________________________________________________________________
```

```python
# í•™ìŠµ
epochs = 15
history = model.fit(
  train_ds,
  validation_data=val_ds,
  epochs=epochs
)
```

## **í›ˆë ¨ ê²°ê³¼ ì‹œê°í™”í•˜ê¸°**

```python
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(epochs)

plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()
```

![]({{ site.url }}{{ site.baseurl }}/assets/images/2022-12-06-CNN_images/Untitled 8.png)

ì´ë¯¸ì§€ ì „ì²˜ë¦¬ì™€ dropoutì„ ì¶”ê°€í•œ ê²°ê³¼ ì˜¤ë²„í”¼íŒ…ì´ ì¼ì–´ë‚˜ì§€ ì•Šì€ ê²ƒì„ í™•ì¸í•˜ì˜€ë‹¤. ê½ƒ ì´ë¯¸ì§€ì—ëŠ” ë…¸ì´ì¦ˆê°€ ë§ê¸° ë•Œë¬¸ì— Accuracy ê°€ ë°ì´í„° ì¦ê°•, Dropoutì„ í–ˆì„ ë•Œ 0.6ëŒ€ì—ì„œ 0.7ì •ë„ë¡œ ì •í™•ë„ê°€ ë†’ì•„ì§„ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

# [ë§ë¼ë¦¬ì•„ ì…€ ì´ë¯¸ì§€](https://lhncbc.nlm.nih.gov/LHC-downloads/downloads.html#malaria-datasets)

- ë§ë¼ë¦¬ì•„ ìŠ¤í¬ë¦¬ë„ˆ ì—°êµ¬ í™œë™ì˜ ë¶„í• ëœ ì„¸í¬ì˜ ì–‡ì€ í˜ˆì•¡ ë„ë§ ìŠ¬ë¼ì´ë“œ ì´ë¯¸ì§€
- ë¦¬ì†ŒìŠ¤ê°€ ì œí•œëœ ì§€ì—­ì—ì„œ í˜„ë¯¸ê²½ ì „ë¬¸ê°€ì˜ ë¶€ë‹´ì„ ì¤„ì´ê³  ì§„ë‹¨ ì •í™•ë„ë¥¼ ê°œì„ í•˜ê¸° ìœ„í•´ NLM(National Library of Medicine)ì˜ ì¼ë¶€ì¸ Lister Hill National Center for Biomedical Communications(LHNCBC)ì˜ ì—°êµ¬ì›ë“¤ì€ ëª¨ë°”ì¼ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê°œë°œ
- ë°©ê¸€ë¼ë°ì‹œ ì¹˜íƒ€ê³µ ì˜ê³¼ëŒ€í•™ ë³‘ì›ì—ì„œ 150ëª…ì˜ P. falciparum ê°ì—¼ìì™€ 50ëª…ì˜ ê±´ê°•í•œ í™˜ìì˜ Giemsa ì—¼ìƒ‰ ì–‡ì€ í˜ˆì•¡ ë„ë§ ìŠ¬ë¼ì´ë“œë¥¼ ìˆ˜ì§‘í•˜ê³  ì‚¬ì§„ì„ ì´¬ì˜
- ì í˜ˆêµ¬ë¥¼ ê°ì§€í•˜ê³  ë¶„í• í•˜ê¸° ìœ„í•´ ë ˆë²¨ ì„¸íŠ¸ ê¸°ë°˜ ì•Œê³ ë¦¬ì¦˜ì„ ì ìš©

```python
# ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
!wget https://data.lhncbc.nlm.nih.gov/public/Malaria/cell_images.zip
```

```python
# images í´ë”ì— ë‹¤ìš´ë¡œë“œ ë°›ì€ íŒŒì¼ ì••ì¶• í•´ì œí•˜ê¸°
!unzip cell_images.zip
```

```python
# ìƒëŒ€ê²½ë¡œëŠ” í†µí•´ cell_images í´ë”ë¥¼ ë¡œë“œ. 
# ì‹¤ìŠµí•˜ê³  ìˆëŠ” íŒŒì¼ê³¼ ê°™ì€ ìœ„ì¹˜ì— images í´ë”ê°€ ìœ„ì¹˜í•´ìˆì–´ì•¼ í´ë”ëª…ë§Œì„ í†µí•´ ê²½ë¡œë¥¼ ì½ì„ ìˆ˜ ìˆë‹¤. 
# images ê²½ë¡œë¥¼ rootë¡œ í•˜ìœ„ ë””ë ‰í† ë¦¬ë¥¼ dirsë¡œ í•´ë‹¹ ê²½ë¡œì— ìˆëŠ” ëª¨ë“  íŒŒì¼ì„ filesë¡œ ë³¼ ìˆ˜ ìˆë‹¤. 
import os
for dirpath, dirnames, filenames in os.walk('cell_images/'):
    print(dirpath, dirnames)
```

```python
# globì€ íŒ¨í„´(ìœ ë‹‰ìŠ¤ ì…¸ì´ ì‚¬ìš©í•˜ëŠ” ê·œì¹™)ì„ ì‚¬ìš©í•˜ì—¬ íŒŒì¼ì„ ê²€ìƒ‰í•˜ëŠ” ëª¨ë“ˆë¡œ 
# í˜„ì¬ ë””ë ‰í„°ë¦¬ì™€ í•˜ìœ„ ë””ë ‰í„°ë¦¬ì˜ ëª¨ë“  í…ìŠ¤íŠ¸íŒŒì¼ì„ ì°¾ì•„ì„œ ì¶œë ¥í•œë‹¤. 
#'./cell_images/*/*.png' íŒŒì¼ ëª©ë¡ì„ ì¶œë ¥í•´ë³´ì.
import glob
paths = glob.glob("./cell_images/*/*.png")
paths[:5]
```

# RGB ìƒ‰ìƒ

### **matplotlibì„ í†µí•œ ì´ë¯¸ì§€ ë°ì´í„°ì˜ RGBê°’ ì´í•´**

ìƒëŒ€ê²½ë¡œë¥¼ ì‚¬ìš©í•´ì„œ ì‹¤ìŠµ ê²½ë¡œì™€ ê°™ì€ ìœ„ì¹˜ì— ìˆëŠ” images í´ë”ì— ìˆëŠ” ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¨ë‹¤. ê·¸ë¦¬ê³  ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ë°°ì—´ í˜•íƒœë¡œ ë§Œë“ ë‹¤. ì´ ë•Œ, matplotlibì˜ `imread` ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë©´ ì´ë¯¸ì§€ë¥¼ ë°°ì—´í˜•íƒœë¡œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆë‹¤.
matplotlib.pyplot ì„ plt ë¼ëŠ” ë³„ì¹­ìœ¼ë¡œ ë¶ˆëŸ¬ì™€ì„œ pyplotì˜ imreadë¡œ íŒŒì¼ì„ ì½ì–´ì˜¨ë‹¤. ì½ì–´ ì˜¨ íŒŒì¼ì„ ì¶œë ¥í•´ ë³´ë©´ 3ê°œì˜ ì±„ë„ì„ ê°–ëŠ” ì´ë¯¸ì§€ ë°°ì—´ì„ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì´ ë•Œ, í–‰ê³¼ ì—´ì˜ ìˆ˜ëŠ” ì´ë¯¸ì§€ì˜ ì„¸ë¡œì™€ ê°€ë¡œ í¬ê¸°ê°€ ëœë‹¤. ì´ë ‡ê²Œ ë¶ˆëŸ¬ì˜¨ ì´ë¯¸ì§€ì˜ R, G, B ê° ì±„ë„ë³„ ë°°ì—´ê°’ì„ í™•ì¸í•´ë³´ì.

```python
import matplotlib.pyplot as plt
img = plt.imread(paths[0])
img.shape

ê²°ê³¼ê°’ : (124, 163, 3)
```

```python
plt.imshow(img)
plt.axis("off")
```

![]({{ site.url }}{{ site.baseurl }}/assets/images/2022-12-06-CNN_images/Untitled 9.png)

ì´ë¯¸ì§€ëŠ” 3ê°œì˜ ì±„ë„ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. íŒŒì´ì¬ì€ ì¸ë±ìŠ¤ ë²ˆí˜¸ê°€ 0ë²ˆë¶€í„° ì‹œì‘í•˜ê¸° ë•Œë¬¸ì— 0, 1, 2 ìœ¼ë¡œ ê°ê° R,G,B ì±„ë„ì— ì ‘ê·¼í•  ìˆ˜ ìˆë‹¤.

```python
# n ë²ˆ ì¸ë±ìŠ¤ ì±„ë„
plt.imshow(img[:,:,0]) # R
plt.imshow(img[:,:,1]) # G
plt.imshow(img[:,:,2]) # B
```

![]({{ site.url }}{{ site.baseurl }}/assets/images/2022-12-06-CNN_images/Untitled 10.png)

## **ì´ë¯¸ì§€ ì²˜ë¦¬ ë„êµ¬**

### **PIL(Python Imaging Library) Pillow**

Python Imaging Library(PIL)ì€ íŒŒì´ì¬ ì¸í„°í”„ë¦¬í„°ì— ë‹¤ì–‘í•œ ì´ë¯¸ì§€ íŒŒì¼ í˜•ì‹ì„ ì§€ì›í•˜ê³  ê°•ë ¥í•œ ì´ë¯¸ì§€ ì²˜ë¦¬ì™€ ê·¸ë˜í”½ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” ììœ -ì˜¤í”ˆ ì†ŒìŠ¤ ì†Œí”„íŠ¸ì›¨ì–´ ë¼ì´ë¸ŒëŸ¬ë¦¬ì´ë‹¤. PIL ì´ë¯¸ì§€ ì‘ì—…ì„ ìœ„í•œ í‘œì¤€ ì ˆì°¨ë¥¼ ì œê³µí•˜ê³  ìˆìœ¼ë©°, ë‹¤ìŒê³¼ ê°™ì€ ê²ƒì´ìˆë‹¤.

- í”½ì…€ ë‹¨ìœ„ì˜ ì¡°ì‘
- ë§ˆìŠ¤í‚¹ ë° íˆ¬ëª…ë„ ì œì–´
- íë¦¼, ìœ¤ê³½ ë³´ì • ë‹¤ë“¬ì–´ ìœ¤ê³½ ê²€ì¶œ ë“±ì˜ ì´ë¯¸ì§€ í•„í„°
- ì„ ëª…í•˜ê²Œ, ë°ê¸° ë³´ì •, ëª…ì•” ë³´ì •, ìƒ‰ ë³´ì • ë“±ì˜ í™”ìƒ ì¡°ì •
- ì´ë¯¸ì§€ì— í…ìŠ¤íŠ¸ ì¶”ê°€
- ê¸°íƒ€ ì—¬ëŸ¬ê°€ì§€

```python
# ì´ë¯¸ì§€ íŒŒì¼ì„ ë§¤ë²ˆ ì§€ì •í•˜ê¸° ë²ˆê±°ë¡­ì§€ ì•Šê²Œ ë³€ìˆ˜ì— ë‹´ì•„ ì¬ì‚¬ìš©
cell_img = paths[1]
cell_img
```

```python
# Image.open ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ë¡œë“œ
from PIL import Image, ImageFilter
original = Image.open(cell_img)
original
```

![]({{ site.url }}{{ site.baseurl }}/assets/images/2022-12-06-CNN_images/Untitled 11.png)

```python
# resize ë¡œ ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆë¥¼ ë³€ê²½
original.resize((150, 150))
```

```python
# save ë¡œ ì´ë¯¸ì§€ë¥¼ ì €ì¥
original.save("original.png")
```

## Open CV

OpenCV(Open Source Computer Vision)ì€ ì‹¤ì‹œê°„ ì»´í“¨í„° ë¹„ì „ì„ ëª©ì ìœ¼ë¡œ í•œ í”„ë¡œê·¸ë˜ë° ë¼ì´ë¸ŒëŸ¬ë¦¬. ì‹¤ì‹œê°„ ì´ë¯¸ì§€ í”„ë¡œì„¸ì‹±ì— ì¤‘ì ì„ ë‘” ë¼ì´ë¸ŒëŸ¬ë¦¬ì´ë‹¤.

### Image Processing in OpenCV

- [OpenCV: Image Processing in OpenCV](https://docs.opencv.org/4.5.2/d2/d96/tutorial_py_table_of_contents_imgproc.html)
- Changing Colorspaces - Learn to change images between different color spaces. Plus learn to track a colored object in a video.
- Geometric Transformations of Images - Learn to apply different geometric transformations to images like rotation, translation etc.
- Image Thresholding - Learn to convert images to binary images using global thresholding, Adaptive thresholding, Otsu's binarization etc
- Smoothing Images - Learn to blur the images, filter the images with custom kernels etc.
- Morphological Transformations - Learn about morphological transformations like Erosion, Dilation, Opening, Closing etc
- Image Gradients - Learn to find image gradients, edges etc.
- Canny Edge Detection - Learn to find edges with Canny Edge Detection
- Image Pyramids - Learn about image pyramids and how to use them for image blending
- Contours in OpenCV - All about Contours in OpenCV
- Histograms in OpenCV - All about histograms in OpenCV
- Image Transforms in OpenCV - Meet different Image Transforms in OpenCV like Fourier Transform, Cosine Transform etc.
- Template Matching - Learn to search for an object in an image using Template Matching
- Hough Line Transform - Learn to detect lines in an image
- Hough Circle Transform - Learn to detect circles in an image
- Image Segmentation with Watershed Algorithm
- Learn to segment images with watershed segmentation
- Interactive Foreground Extraction using GrabCut Algorithm
- Learn to extract foreground with GrabCut algorithm

## í˜„ì¬ ë‚´ìš© ì •ë¦¬

ë§ë¼ë¦¬ì•„ í˜ˆì•¡ë„ë§ ì´ë¯¸ì§€ ë¶„ë¥˜ ì‹¤ìŠµì„ ì§„í–‰í•˜ê¸° ìœ„í•´ ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë°©ë²•ê³¼ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ë¥¼ ì–´ë–»ê²Œ í•´ì£¼ëŠ”ê°€ì— ëŒ€í•´ í•™ìŠµí•˜ì˜€ë‹¤. ë‹¤ìŒìœ¼ë¡œëŠ” TF ê³µì‹ë¬¸ì„œì˜ ì´ë¯¸ì§€ ë¶„ë¥˜ë¥¼ ë‹¤ë¥¸ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•´ì„œ ì‘ìš©í•´ë³´ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•œë‹¤.

## ì¼ë¶€ ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸°

```python
import glob
upics = glob.glob('./cell_images/Uninfected/*.png')
apics = glob.glob('./cell_images/Parasitized/*.png')
len(upics), upics[0], len(apics), apics[0]
```

```python
# upics 
# matplotlib ìœ¼ë¡œ ë¶ˆëŸ¬ì˜¨ ë°©ë²•

upics_0 = upics[0]
upics_0_img = plt.imread(upics_0)
plt.imshow(upics_0_img)
```

![]({{ site.url }}{{ site.baseurl }}/assets/images/2022-12-06-CNN_images/Untitled 12.png)

```python
# apics
# matplotlib ìœ¼ë¡œ ë¶ˆëŸ¬ì˜¨ ë°©ë²•

apics_0 = apics[0]
apics_0_img = plt.imread(apics_0)
plt.imshow(apics_0_img)
```

![]({{ site.url }}{{ site.baseurl }}/assets/images/2022-12-06-CNN_images/Untitled 13.png)

```python
# cv2 ë¡œ Uninfected ì‹œê°í™”
import cv2

plt.figure(figsize=(8, 8))
labels = "Uninfected"
for i, images in enumerate(upics[:9]):
    ax = plt.subplot(3, 3, i + 1)
    img = cv2.imread(images)
    plt.imshow(img)
    plt.title(f'{labels} {img.shape}')
    plt.axis("off")
```

![]({{ site.url }}{{ site.baseurl }}/assets/images/2022-12-06-CNN_images/Untitled 14.png)

```python
# cv2 ë¡œ Infected ì‹œê°í™”
plt.figure(figsize=(8, 8))
labels = "Infected"
for i, images in enumerate(apics[:9]):
    ax = plt.subplot(3, 3, i + 1)
    img = cv2.imread(images)
    plt.imshow(img)
    plt.title(f'{labels} {img.shape}')
    plt.axis("off")
```

![]({{ site.url }}{{ site.baseurl }}/assets/images/2022-12-06-CNN_images/Untitled 15.png)

## ë°ì´í„°ì…‹ ë‚˜ëˆ„ê¸°

`Keras`ì˜ `ImageDataGenerater`ë¡œ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬ë¥¼ ì§„í–‰í•œë‹¤. `Keras`ì˜ `ImageDataGenerator`ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì´ë¯¸ì§€ ë³€í™˜ ìœ í˜•ì„ ì§€ì›í•œë‹¤.

ê³µê°„ ë ˆë²¨ ë³€í˜•

- Flip : ìƒí•˜, ì¢Œìš° ë°˜ì „
- Rotation : íšŒì „
- Shift : ì´ë™
- Zoom : í™•ëŒ€, ì¶•ì†Œ
- Shear : ëˆ•íˆê¸°

í”½ì…€ ë ˆë²¨ ë³€í˜•

- Bright : ë°ê¸° ì¡°ì •
- Channel Shift : RGB ê°’ ë³€ê²½
- ZCA Whitening : Whitening íš¨ê³¼

```python
# ImageDataGeneratorë¥¼ í†µí•´ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬ 
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# validation_split ê°’ì„ í†µí•´ í•™ìŠµ:ê²€ì¦ ë¹„ìœ¨ì„ 8:2 ë¡œ ë‚˜ëˆ„ê¸°
datagen = ImageDataGenerator(rescale=1/255.0, validation_split=0.2)
```

## ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆ ì„¤ì •

```python
width = 32
height = 32
```

ğŸ¤” **ì›ë³¸ì´ë¯¸ì§€ì™€ ë¹„êµí–ˆì„ ë•Œ ê¶Œì¥í•˜ëŠ” ì´ë¯¸ì§€ í¬ê¸°ëŠ” ë”°ë¡œ ì—†ë‚˜ìš”?**

ìƒí™©ì— ë”°ë¼ ë‹¤ë¥´ë‹¤. ì¥ë¹„ê°€ ì—°ì‚°ì„ ë§ì´ ì§€ì›í•  ìˆ˜ ìˆë‹¤ë©´ ì›ë³¸ ì‚¬ì´ì¦ˆë¥¼ ì‚¬ìš©í•˜ê³  ì¥ë¹„ ê³„ì‚°ì´ ë„ˆë¬´ ì˜¤ë˜ ê±¸ë¦°ë‹¤ë©´ ì¤„ì—¬ì£¼ëŠ” ê²ƒì´ ì¢‹ë‹¤. 
ì´ë¯¸ì§€ì˜ ì‚¬ì´ì¦ˆëŠ” ì„ì˜ëŒ€ë¡œ í•´ë„ ìƒê´€ì—†ì§€ë§Œ,  ë”¥ëŸ¬ë‹ì˜ ê²½ìš° Network ëª¨ë¸ì˜ ì…ë ¥ ì‚¬ì´ì¦ˆì™€ ë°˜ë“œì‹œ ë™ì¼í•˜ê²Œ í•´ì¤˜ì•¼ í•œë‹¤. ì°¸ê³ ë¡œ CNNì˜ ëŒ€í‘œì ì¸ ëª¨ë¸ë“¤ì€ ë„¤íŠ¸ì›Œí¬ ì…ë ¥ì‚¬ì´ì¦ˆê°€ 224 * 224ì¸ ê²½ìš°ê°€ ë§ë‹¤.

### í•™ìŠµ ë° ê²€ì¦ ì„¸íŠ¸

`flow_from_directory`ë¥¼ í†µí•´ ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¤ê³  training ë°ì´í„°ì…‹ì„ ìƒì„±í•œë‹¤. class_modeì—ëŠ” ì´ì§„ë¶„ë¥˜(ê°ì—¼ ì—¬ë¶€ íŒë‹¨)ì´ê¸° ë•Œë¬¸ì— binaryë¥¼ ë„£ì–´ì¤€ë‹¤.

```python
# class_mode: One of "categorical", "binary", "sparse","input", or None. Default: "categorical".
# subset: Subset of data ("training" or "validation")
trainDatagen = datagen.flow_from_directory(directory = 'cell_images/',
                                           target_size = (height, width),
                                           class_mode = 'binary',
                                           batch_size = 64,
                                           subset='training')
```

```python
trainDatagen.num_classes
ê²°ê³¼ê°’ : 2
```

```python
trainDatagen.classes
ê²°ê³¼ê°’ : array([0, 0, 0, ..., 1, 1, 1], dtype=int32)
```

Validation setì„ ìƒì„±í•˜ë„ë¡ê³  í•œë‹¤.

```python
# validation ë°ì´í„°ì…‹ì„ ìƒì„±
valDatagen = datagen.flow_from_directory(directory = 'cell_images/',
                                         target_size =(height, width),
                                         class_mode = 'binary',
                                         batch_size = 64,
                                         subset='validation')
```

```python
# 0 : ê°ì—¼, 1 : ê°ì—¼ ì•ˆ ë¨

valDatagen.class_indices
ê²°ê³¼ê°’ : {'Parasitized': 0, 'Uninfected': 1}
```

## ìš”ì•½

- ì£¼ì œ:  ë§ë¼ë¦¬ì•„ í˜ˆì•¡ë„ë§ ì´ë¯¸ì§€ ë¶„ë¥˜ ì‹¤ìŠµ
- ëª©ì :  TFê³µì‹ ë¬¸ì„œì˜ ì´ë¯¸ì§€ ë¶„ë¥˜ë¥¼ ë‹¤ë¥¸ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•´ì„œ ì‘ìš©
1. ì´ë¯¸ì§€ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° wgetì„ ì‚¬ìš©í•˜ë©´ ì˜¨ë¼ì¸ URL ì— ìˆëŠ” íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆë‹¤. ë…¼ë¬¸(í˜ˆì•¡ë„ë§ ì´ë¯¸ì§€ë¡œ ë§ë¼ë¦¬ì•„ ê°ì—¼ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ëŠ” ë…¼ë¬¸)ì— ì‚¬ìš©í•œ ë°ì´í„°ì…‹ì„ ë¶ˆëŸ¬ì™”ë‹¤.
2. `plt.imread` ì™€ `cv2(OpenCV)`ì˜ `imread`ë¥¼ í†µí•´ array í˜•íƒœë¡œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™€ì„œ ì‹œê°í™”ë¥¼ í•´ì„œ ê°ì—¼ëœ ì´ë¯¸ì§€ì™€ ì•„ë‹Œ ì´ë¯¸ì§€ë¥¼ ë¹„êµí•˜ì˜€ë‹¤.
3. `TF.keras`ì˜ ì „ì²˜ë¦¬ ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì„œ train, valid setì„ ë‚˜ëˆ ì£¼ì—ˆë‹¤ â‡’ ë ˆì´ë¸”ê°’ì„ í´ë”ëª…ìœ¼ë¡œ ìƒì„±

ì•ìœ¼ë¡œ í•  ë‚´ìš©ì€ CNN ë ˆì´ì–´ë¥¼ êµ¬ì„±, ì»´íŒŒì¼ í•˜ê³  í•™ìŠµí•˜ê³  ì •í™•ë„(Accuray) ì„±ëŠ¥ì„ ë¹„êµí•´ë³¼ ì˜ˆì •

## ëª¨ë¸ êµ¬ì„± ë° í•™ìŠµê³¼ ì˜ˆì¸¡

### ë ˆì´ì–´ êµ¬ì„±

```python
model = Sequential()
# ì…ë ¥ì¸µ
model.add(Conv2D(filters=16, kernel_size=(3,3), padding='valid',
                 activation='relu', input_shape=(height, width, 3)))
model.add(MaxPool2D(pool_size=(2,2), strides=1))

model.add(Conv2D(filters=16, kernel_size=(3,3), padding='same',
                 activation='relu'))
model.add(Conv2D(filters=16, kernel_size=(3,3), padding='same',
                 activation='relu'))
model.add(MaxPool2D(pool_size=(2,2), strides=1))

model.add(Conv2D(filters=16, kernel_size=(3,3), padding='same',
                 activation='relu'))
model.add(Conv2D(filters=16, kernel_size=(3,3), padding='same',
                 activation='relu'))
model.add(MaxPool2D(pool_size=(2,2), strides=1))

# Fully-connected layer
model.add(Flatten())
model.add(Dense(units = 64, activation = "relu"))
model.add(Dropout(0.2))
model.add(Dense(units = 32, activation = "relu"))
model.add(Dropout(0.2))

# ì¶œë ¥ì¸µ
model.add(Dense(1, activation='sigmoid'))
```

**ğŸ’¡ Padding ì˜µì…˜ì˜ vaildì™€ sameì˜ ì°¨ì´ì **

conv2dì¸µì˜ padding ë§¤ê°œë³€ìˆ˜ì˜ ê¸°ë³¸ê°’ì€ `"vaild"`ë¡œ ì»¤ë„ì´ ì¸í’‹ ì´ë¯¸ì§€ ë°–ìœ¼ë¡œ ìŠ¬ë¼ì´ë”© í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì´ëŸ° ê²½ìš° ì¶œë ¥ì€ ì…ë ¥ë³´ë‹¤ ì‘ì•„ì§€ê²Œ ëœë‹¤.
padding ë§¤ê°œë³€ìˆ˜ë¥¼ `"same"`ìœ¼ë¡œ í•´ì¤„ ê²½ìš° ì¶œë ¥ í¬ê¸°ê°€ ì…ë ¥ê°’ê³¼ ë™ì¼í•´ì§€ë„ë¡ ì…ë ¥ ì´ë¯¸ì§€ ì£¼ìœ„ì— 0 í”½ì…€ì´ íŒ¨ë”©ëœë‹¤.

**ğŸ¤” ë¹„ì„ í˜• í™œì„±í™” í•¨ìˆ˜(Activation function)ê°€ ì—†ì´ ì—¬ëŸ¬ ê°œì˜ ì¸µì„ ìŒ“ì„ ê²½ìš°?**

ë¹„ì„ í˜• í™œì„±í™” í•¨ìˆ˜ê°€ ì—†ì´ ì—¬ëŸ¬ ê°œì˜ ì¸µì„ ìŒ“ì„ ê²½ìš° ê¸°ë³¸ ì„ í˜• í™œì„±í™” í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ê²Œ ë˜ë¯€ë¡œ í•˜ë‚˜ì˜ ì¸µì„ ê°€ì§„ ì„ í˜• ëª¨ë¸ê³¼ ì„±ëŠ¥ì´ ë¹„ìŠ·í•˜ë‹¤.
ì€ë‹‰ì¸µì— ë¹„ì„ í˜• í™œì„±í™” í•¨ìˆ˜ë¥¼ ì¶”ê°€í•˜ì§€ ì•Šìœ¼ë©´ ê³„ì‚° ìì›ê³¼ ì‹œê°„ì„ ë‚­ë¹„í•˜ëŠ” ê²°ê³¼ë¥¼ ì´ˆë˜í•˜ê³  ìˆ˜ì¹˜ì ìœ¼ë¡œ ë¶ˆì•ˆì •ì„±ì´ ë†’ì•„ì§€ê²Œ ëœë‹¤.
ì´ëŸ° í˜„ìƒì€ ë°€ì§‘ ì¸µ ë¿ë§Œ ì•„ë‹ˆë¼ ì•„ê¹Œ ë§í•œ í•©ì„±ê³± ì¸µê³¼ ê°™ì´ ë‹¤ë¥¸ ì¢…ë¥˜ì˜ ì¸µì—ë„ ì ìš©ë˜ê²Œ ëœë‹¤.
(ì˜ˆë¥¼ ë“¤ì–´ "ë¹„ì„ í˜• í™œì„±í™” í•¨ìˆ˜ ì—†ì´"  ë‘ ê°œì˜ í•©ì„±ê³± ì¸µì„ ìŒ“ëŠ” ê²½ìš° ê·¸ëƒ¥ ë§ì€ ì»¤ë„ì„ ê°€ì§„ í•˜ë‚˜ì˜ conv2d ì¸µì„ ì‚¬ìš©í•˜ëŠ” ê²ƒê³¼ ìˆ˜í•™ì ìœ¼ë¡œ ë™ì¼í•˜ê¸° ë•Œë¬¸ì— ë¹„íš¨ìœ¨ ì ìœ¼ë¡œ í•©ì„±ê³± ì‹ ê²½ë§ì„ ë§Œë“œëŠ” ê²ƒê³¼ ë‹¤ë¦„ì—†ë‹¤!)

### ëª¨ë¸ ìš”ì•½

```python
# summary
model.summary()
```

```
Model: "sequential_3"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_15 (Conv2D)          (None, 30, 30, 16)        448       
                                                                 
 max_pooling2d_9 (MaxPooling  (None, 29, 29, 16)       0         
 2D)                                                             
                                                                 
 conv2d_16 (Conv2D)          (None, 29, 29, 16)        2320      
                                                                 
 conv2d_17 (Conv2D)          (None, 29, 29, 16)        2320      
                                                                 
 max_pooling2d_10 (MaxPoolin  (None, 28, 28, 16)       0         
 g2D)                                                            
                                                                 
 conv2d_18 (Conv2D)          (None, 28, 28, 16)        2320      
                                                                 
 conv2d_19 (Conv2D)          (None, 28, 28, 16)        2320      
                                                                 
 max_pooling2d_11 (MaxPoolin  (None, 27, 27, 16)       0         
 g2D)                                                            
                                                                 
 flatten_3 (Flatten)         (None, 11664)             0         
                                                                 
 dense_5 (Dense)             (None, 64)                746560    
                                                                 
 dropout_2 (Dropout)         (None, 64)                0         
                                                                 
 dense_6 (Dense)             (None, 32)                2080      
                                                                 
 dropout_3 (Dropout)         (None, 32)                0         
                                                                 
 dense_7 (Dense)             (None, 1)                 33        
                                                                 
=================================================================
Total params: 758,401
Trainable params: 758,401
Non-trainable params: 0
_________________________________________________________________
```

```python
# tensorflow.keras.utilsì˜ plot_model ì„ í†µí•œ ë ˆì´ì–´ ì‹œê°í™”
from tensorflow.keras.utils import plot_model

plot_model(model)
```

![]({{ site.url }}{{ site.baseurl }}/assets/images/2022-12-06-CNN_images/Untitled 16.png)

### ì»´íŒŒì¼

```python
# model.compile
# ì˜µí‹°ë§ˆì´ì € 'adam'
# ì†ì‹¤í•¨ìˆ˜ ì´ì§„ë¶„ë¥˜
# ì¸¡ì •ì§€í‘œ 'accuracy'

model.compile(optimizer = "adam",
              loss = "binary_crossentropy", metrics = "accuracy")
```

### í•™ìŠµ

```python
early_stop = EarlyStopping(monitor='val_loss', patience=10)
```

```python
# fit
history = model.fit(trainDatagen, validation_data = valDatagen, epochs = 30, verbose = 2, callbacks = early_stop)
```

```python
# history
df_hist = pd.DataFrame(history.history)
df_hist.tail(3)
```

| loss | accuracy | val_loss | val_accuracy |
| --- | --- | --- | --- |
| 14 | 0.072565 | 0.976007 | 0.199645 |
| 15 | 0.062142 | 0.979000 | 0.235941 |
| 16 | 0.059259 | 0.979272 | 0.201430 |

```python
df_hist[["loss", "val_loss"]].plot()
```

![]({{ site.url }}{{ site.baseurl }}/assets/images/2022-12-06-CNN_images/Untitled 17.png)

```python
df_hist[["accuracy", "val_accuracy"]].plot()
```

![]({{ site.url }}{{ site.baseurl }}/assets/images/2022-12-06-CNN_images/Untitled 18.png)

ğŸ’¡ **ì…ë ¥ ë°ì´í„° ì¢…ë¥˜ì™€ ì´ì— ë§ëŠ” ë„¤íŠ¸ì›Œí¬ êµ¬ì¡°ì— ëŒ€í•´ ì •ë¦¬**

- ë²¡í„° ë°ì´í„°(ì‹œê°„ì´ë‚˜ ìˆœì„œê°€ ìƒê´€ ì—†ìŒ): MLP (ë°€ì§‘ì¸µ)
- ì´ë¯¸ì§€ ë°ì´í„°(í‘ë°± ë˜ëŠ” ì»¬ëŸ¬): 2D í•©ì„±ê³± ì‹ ê²½ë§
- ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ì˜¤ë””ì˜¤ ë°ì´í„°: 2D í•©ì„±ê³± ì‹ ê²½ë§ì´ë‚˜ ìˆœí™˜ ì‹ ê²½ë§
- í…ìŠ¤íŠ¸ ë°ì´í„°: 1D í•©ì„±ê³± ì‹ ê²½ë§ì´ë‚˜ ìˆœí™˜ ì‹ ê²½ë§
- ì‹œê³„ì—´ ë°ì´í„°(ì‹œê°„ì´ë‚˜ ìˆœì„œê°€ ì¤‘ìš”í•¨): 1D í•©ì„±ê³± ì‹ ê²½ë§ì´ë‚˜ ìˆœí™˜ ì‹ ê²½ë§
- ë³¼ë¥¨ ë°ì´í„°(ì˜ˆ: 3D ì˜ë£Œ ì´ë¯¸ì§€): 3D í•©ì„±ê³± ì‹ ê²½ë§
- ë¹„ë””ì˜¤ ë°ì´í„°(ì´ë¯¸ì§€ì˜ ì‹œí€€ìŠ¤): 3D í•©ì„±ê³± ì‹ ê²½ë§(ëª¨ì…˜ íš¨ê³¼ë¥¼ ê°ì§€í•´ì•¼ í•˜ëŠ” ê²½ìš°) ë˜ëŠ” íŠ¹ì„± ì¶”ì¶œì„ ìœ„í•´ í”„ë ˆì„ ë³„ë¡œ ì ìš©í•œ 2D í•©ì„±ê³± ì‹ ê²½ë§ê³¼ ë§Œë“¤ì–´ì§„ íŠ¹ì„± ì‹œí€€ìŠ¤ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ RNNì´ë‚˜ 1D í•©ì„±ê³± ì‹ ê²½ë§ì˜ ì¡°í•©

ì§€ê¸ˆì€ ì´ ì¤‘ì— 2D í•©ì„±ê³± ì‹ ê²½ë§ì„ í†µí•œ ì´ë¯¸ì§€ ë°ì´í„° í•™ìŠµëª¨ë¸ì— ëŒ€í•´ ì§„í–‰ì„ í•˜ê³  ìˆë‹¤.

**ğŸ’¡ í•©ì„±ê³± ì‹ ê²½ë§ì— ëŒ€í•œ ì •ë¦¬**

í•©ì„±ê³± ì¸µì€ ì…ë ¥ë°›ì€ í…ì„œì—ì„œ ê³µê°„ì ìœ¼ë¡œ ë‹¤ë¥¸ ìœ„ì¹˜ì— ê¸°í•˜í•™ì  ë³€í™˜ì„ ì ìš©í•˜ì—¬ êµ­ë¶€ì ì¸ ê³µê°„ íŒ¨í„´ì„ ì°¾ëŠ”ë‹¤. ì´ëŸ° ë°©ì‹ì€ ì´ë™ ë¶ˆë³€ì„±ì„ ê°€ì§„ í‘œí˜„ì„ ë§Œë“¤ê¸° ë•Œë¬¸ì— í•©ì„±ê³± ì¸µì„ ë§¤ìš° ë°ì´í„° íš¨ìœ¨ì ìœ¼ë¡œ ë§Œë“¤ê³  ëª¨ë“ˆí™”ì‹œí‚¨ë‹¤. 
ìœ„ì™€ ê°™ì€ ì•„ì´ë””ì–´ëŠ” ì–´ë–¤ ì°¨ì› ê³µê°„ì—ë„ ì ìš©í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— 1D(ì‹œí€€ìŠ¤), 2D(ì´ë¯¸ì§€ë‚˜ ì´ë¯¸ì§€ê°€ ì•„ë‹ˆìë§Œ ì‚¬ìš´ë“œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ì²˜ëŸ¼ ë¹„ìŠ·í•œ í‘œí˜„), 3D(ë³¼ë¥¨ ë°ì´í„°) ë“±ì— ì ìš©í•  ìˆ˜ ìˆë‹¤. 
í…ì„œí”Œë¡œìš°ì—ì„œëŠ” conv1d ì¸µìœ¼ë¡œ ì‹œí€€ìŠ¤ë¥¼ ì²˜ë¦¬í•˜ê³ , conv2dì¸µìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•˜ê³ , conv3d ì¸µìœ¼ë¡œ ë³¼ë¥¨ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆë‹¤. 
í•©ì„±ê³± ì‹ ê²½ë§ì€ í•©ì„±ê³± ì¸µê³¼ í’€ë§ ì¸µì„ ìŒ“ì•„ì„œ êµ¬ì„±í•˜ê²Œ ëœë‹¤. í’€ë§ ì¸µì€ ê³µê°„ì ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë‹¤ìš´ìƒ˜í”Œë§í•˜ê³  ì´ëŠ” íŠ¹ì„± ê°œìˆ˜ê°€ ëŠ˜ì–´ë‚˜ê²Œë˜ë©´ í›„ì†ì¸µì´ í•©ì„±ê³± ì‹ ê²½ë§ì˜ ì…ë ¥ ì´ë¯¸ì§€ì—ì„œ ë” ë§ì€ ê³µê°„ì„ ë°”ë¼ë³´ë„ë¡ íŠ¹ì„± ë§µì˜ í¬ê¸°ë¥¼ ì ì ˆí•˜ê²Œ ìœ ì§€ì‹œí‚¨ë‹¤. 
í•©ì„±ê³± ì‹ ê²½ë§ì€ ê³µê°„ì ì¸ íŠ¹ì„± ë§µì„ ë²¡í„°ë¡œ ë°”ê¾¸ê¸° ìœ„í•´ ì¢…ì¢… flattenì¸µê³¼ ì „ì—­ í’€ë§ ì¸µìœ¼ë¡œ ëë‚˜ê¸°ë„ í•œë‹¤. ê·¸ë¦¬ê³  ì¼ë ¨ì˜ ë°€ì§‘ì¸µ(MLP)ë¡œ ì²˜ë¦¬í•˜ì—¬ ë¶„ë¥˜ë‚˜ íšŒê·€ ì¶œë ¥ì„ ë§Œë“¤ê²Œ ëœë‹¤.